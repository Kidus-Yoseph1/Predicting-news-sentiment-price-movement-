{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe98625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "\n",
    "from financial_analysis import process_all_stocks, calculate_daily_returns, calculate_correlation\n",
    "from sentiment_analyzer import perform_sentiment_analysis, aggregate_daily_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89c60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCK_DATA_DIR = '../data/yfinance_data/Data' \n",
    "NEWS_DATA_PATH = '../data/newsData/raw_analyst_ratings.csv'\n",
    "PROCESSED_NEWS_PATH = '../data/newsData/processed_sentiment_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9b0b0",
   "metadata": {},
   "source": [
    "#### Daily Returns Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69238004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indicators for AAPL...\n",
      "Processing indicators for AMZN...\n",
      "Processing indicators for GOOG...\n",
      "Processing indicators for META...\n",
      "Processing indicators for MSFT...\n",
      "Processing indicators for NVDA...\n",
      "Daily Returns calculated for 6 stocks.\n"
     ]
    }
   ],
   "source": [
    "all_stocks_indicators = process_all_stocks(STOCK_DATA_DIR)\n",
    "\n",
    "all_returns_list = []\n",
    "for ticker, df in all_stocks_indicators.items():\n",
    "    # calculate_daily_returns is responsible for computing daily percentage change in prices\n",
    "    df_returns = calculate_daily_returns(df)\n",
    "    all_returns_list.append(df_returns)\n",
    "\n",
    "all_stocks_returns_df = pd.concat(all_returns_list, ignore_index=True)\n",
    "print(f\"Daily Returns calculated for {len(all_stocks_returns_df['Ticker'].unique())} stocks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0f789",
   "metadata": {},
   "source": [
    "### Sentiment Analysis and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd60fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/kidus/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce403c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found. Beginning sentiment calculation on 1.4M rows...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"2020-05-22 00:00:00\" doesn't match format \"%Y-%m-%d %H:%M:%S%z\", at position 10. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m news_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(NEWS_DATA_PATH) \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Perform Sentiment Analysis\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m sentiment_df \u001b[38;5;241m=\u001b[39m \u001b[43mperform_sentiment_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Save the result for fast loading next time\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculation complete. Saving processed data to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROCESSED_NEWS_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/kidus/Local_Disk/Development/1.KAIM/Predicting-news-sentiment-price-movement-/src/sentiment_analyzer.py:19\u001b[0m, in \u001b[0;36mperform_sentiment_analysis\u001b[0;34m(df, headline_col, date_col)\u001b[0m\n\u001b[1;32m     16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[headline_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: sid\u001b[38;5;241m.\u001b[39mpolarity_scores(\u001b[38;5;28mstr\u001b[39m(x))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Normalize Date/Time column to just the date (Date Alignment)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mnormalize()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Assuming news data has a column for the stock ticker\u001b[39;00m\n\u001b[1;32m     22\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_base/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1068\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1068\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1070\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_base/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:249\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    247\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 249\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_base/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    438\u001b[0m     arg,\n\u001b[1;32m    439\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m )\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_base/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:469\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    459\u001b[0m     arg,\n\u001b[1;32m    460\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mpandas/_libs/tslibs/strptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/tslibs/strptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/tslibs/strptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"2020-05-22 00:00:00\" doesn't match format \"%Y-%m-%d %H:%M:%S%z\", at position 10. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "if os.path.exists(PROCESSED_NEWS_PATH):\n",
    "    print(f\"Loading pre-calculated sentiment data from {PROCESSED_NEWS_PATH}...\")\n",
    "    # Load the saved DataFrame, ensuring 'Date' is parsed correctly\n",
    "    sentiment_df = pd.read_csv(PROCESSED_NEWS_PATH, parse_dates=['Date'])\n",
    "    \n",
    "else:\n",
    "    print(f\"File not found. Beginning sentiment calculation on 1.4M rows...\")\n",
    "    try:\n",
    "        # Load News Data\n",
    "        news_df = pd.read_csv(NEWS_DATA_PATH) \n",
    "\n",
    "        # Perform Sentiment Analysis\n",
    "        sentiment_df = perform_sentiment_analysis(news_df)\n",
    "        \n",
    "        # Save the result for fast loading next time\n",
    "        print(f\"Calculation complete. Saving processed data to {PROCESSED_NEWS_PATH}...\")\n",
    "        sentiment_df.to_csv(PROCESSED_NEWS_PATH, index=False)\n",
    "\n",
    "    except LookupError:\n",
    "        print(\"\\n NLTK Error: The VADER lexicon is missing. Run the download command.\")\n",
    "        sys.exit()\n",
    "\n",
    "daily_sentiment_df = aggregate_daily_sentiment(sentiment_df)\n",
    "print(\"Daily aggregated sentiment scores calculated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2f69b",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df, correlation_results = calculate_correlation(all_stocks_returns_df, daily_sentiment_df)\n",
    "\n",
    "print(\"\\nPearson Correlation Results (Sentiment vs. Daily Returns):\")\n",
    "print(correlation_results.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e68a99",
   "metadata": {},
   "source": [
    "#### Visualization for Correlation KPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one stock (e.g., AAPL) for the correlation scatter plot ticker_to_plot = 'AAPL' \n",
    "ticker_to_plot = 'AAPL'\n",
    "aapl_corr_df = combined_df[combined_df['Ticker'] == ticker_to_plot]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(aapl_corr_df['avg_daily_sentiment'], aapl_corr_df['Daily_Return'], \n",
    "            alpha=0.6, edgecolors='w', linewidth=0.5)\n",
    "\n",
    "# Add correlation value to the plot\n",
    "aapl_corr_value = correlation_results[correlation_results['Ticker'] == ticker_to_plot]['Pearson_Correlation'].iloc[0]\n",
    "\n",
    "plt.title(f'{ticker_to_plot}: Daily Sentiment vs. Daily Stock Returns', fontsize=14)\n",
    "plt.xlabel('Average Daily Sentiment Score (VADER Compound)', fontsize=12)\n",
    "plt.ylabel('Daily Stock Return (%)', fontsize=12)\n",
    "plt.suptitle(f'Pearson Correlation Coefficient: {aapl_corr_value:.4f}', y=0.95, fontsize=16)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049a2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
